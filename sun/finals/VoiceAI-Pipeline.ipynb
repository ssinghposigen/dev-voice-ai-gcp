{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6ac08b-3980-422d-a165-df3fbaa733f8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5cfd177-51e0-4c1e-8afe-26f581538106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl, compiler, components\n",
    "from kfp.dsl import component\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16409781-492e-4507-a1d3-50d11a3e6bea",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "23fa675f-1adb-426d-9bb0-ec81b5c49174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/9hxy68396zv73__y8rdf3jlc0000gn/T/ipykernel_16690/4257710002.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  TIMESTAMP = datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
     ]
    }
   ],
   "source": [
    "# Temporary secrets manager\n",
    "with open(\"configs.json\", 'r') as secrets_file:\n",
    "    configs = json.load(secrets_file)\n",
    "\n",
    "max_objects = 1\n",
    "\n",
    "# Generate timestamp in a Vertex-compatible format\n",
    "TIMESTAMP = datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "VAI_GCP_PROJECT_ID = configs.get(\"VAI_GCP_PROJECT_ID\")\n",
    "VAI_GCP_PROJECT_LOCATION = configs.get(\"VAI_GCP_PROJECT_LOCATION\")\n",
    "VAI_GCP_PIPELINE_BUCKET = configs.get(\"VAI_GCP_PIPELINE_BUCKET\")\n",
    "\n",
    "VAI_GCP_PIPELINE_RUN_NAME = f\"{configs.get(\"VAI_GCP_PIPELINE_NAME\")}-{TIMESTAMP}\"\n",
    "GCP_PIPELINE_ROOT = f\"gs://{VAI_GCP_PIPELINE_BUCKET}/{VAI_GCP_PIPELINE_RUN_NAME}\"\n",
    "\n",
    "VAI_AWS_ACCESS_KEY = configs.get(\"VAI_AWS_ACCESS_KEY\")\n",
    "VAI_AWS_SECRET_KEY = configs.get(\"VAI_AWS_SECRET_KEY\")\n",
    "\n",
    "VAI_S3_ANALYSIS_BUCKET = configs.get(\"VAI_S3_ANALYSIS_BUCKET\")\n",
    "VAI_S3_TRANSCRIPTS_LOCATION = configs.get(\"VAI_S3_TRANSCRIPTS_LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da519ced-6d4f-443e-bfc0-9bb18b3046f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VAI_PIPELINE_RUN-2025-03-02-17-00-46'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAI_GCP_PIPELINE_RUN_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f11fb1-562e-4d6b-9470-c6d80b21445c",
   "metadata": {},
   "source": [
    "# Set up Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5b7a7884-05bf-4ae3-8755-0bcc5982c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "def setup_logger():\n",
    "    \"\"\"Set up a logger for the pipeline run.\"\"\"\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adbac45-d2c4-4163-a463-9b768a0ff1e4",
   "metadata": {},
   "source": [
    "# Set up Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b1e6715d-d5d0-4d5a-9c54-6b1d13a02a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_exception(\n",
    "    file_id: str,\n",
    "    vai_gcs_bucket: str,\n",
    "    run_folder: str,\n",
    "    error_folder: str,\n",
    "    error_message: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Logs the error, appends the file_id to error tracking CSV, and triggers a notification.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        error_df_path = f\"{error_folder}/{run_folder}_errors.csv\"\n",
    "\n",
    "        logger.error(f\"Error processing file {file_id}: {error_message}\")\n",
    "\n",
    "        gcs_client = storage.Client()\n",
    "        bucket = gcs_client.bucket(vai_gcs_bucket)\n",
    "        blob = bucket.blob(error_df_path)\n",
    "\n",
    "        if blob.exists():\n",
    "            error_df = pd.read_csv(f\"gs://{vai_gcs_bucket}/{error_df_path}\")\n",
    "        else:\n",
    "            error_df = pd.DataFrame(columns=[\"File_ID\", \"Error_Message\"])\n",
    "\n",
    "        error_df = pd.concat([error_df, pd.DataFrame([{\"File_ID\": file_id, \"Error_Message\": error_message}])], ignore_index=True)\n",
    "        error_df.to_csv(f\"gs://{vai_gcs_bucket}/{error_df_path}\", index=False)\n",
    "        logger.info(f\"Logged error for file {file_id} in {error_df_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to write to error tracking file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f6044-2073-4ba7-b4d4-bccfa22d8109",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Component: Listing new Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3606d87-7c12-4582-8809-537e82b46d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_run_name=VAI_GCP_PIPELINE_RUN_NAME\n",
    "# aws_access_key=VAI_AWS_ACCESS_KEY\n",
    "# aws_secret_key=VAI_AWS_SECRET_KEY\n",
    "# s3_analysis_bucket=VAI_S3_ANALYSIS_BUCKET\n",
    "# s3_transcript_location=VAI_S3_TRANSCRIPTS_LOCATION\n",
    "# vai_gcs_bucket=VAI_GCP_PIPELINE_BUCKET\n",
    "# max_objects=max_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e570f4d8-4ad7-4f1e-88ce-bf6f46fb19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=f\"us-central1-docker.pkg.dev/dev-posigen/dev-voice-ai/voice-ai-docker-image:latest\"\n",
    ")\n",
    "def list_s3_files_to_gcs(\n",
    "    pipeline_run_name: str,\n",
    "    aws_access_key: str,\n",
    "    aws_secret_key: str,\n",
    "    s3_analysis_bucket: str,\n",
    "    s3_transcript_location: str,\n",
    "    vai_gcs_bucket: str,  \n",
    "    max_objects: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch audio file from S3 and return it as a BytesIO object\n",
    "    \"\"\"\n",
    "    import boto3\n",
    "    import pandas as pd\n",
    "    import logging\n",
    "    from google.cloud import storage\n",
    "    from datetime import datetime\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    try:\n",
    "        # Generate pipeline folder paths\n",
    "        staging_folder = f\"{pipeline_run_name}/Stagging\"\n",
    "        errored_folder = f\"{pipeline_run_name}/Errored\"\n",
    "        \n",
    "        # Initialize GCS Client\n",
    "        gcs_client = storage.Client()\n",
    "        bucket = gcs_client.bucket(vai_gcs_bucket)\n",
    "        \n",
    "        # ðŸ”¹ Corrected: Create empty folders directly\n",
    "        for folder in [staging_folder, errored_folder]:\n",
    "            blob = bucket.blob(f\"{folder}/\")\n",
    "            blob.upload_from_string(\"\", content_type=\"application/x-www-form-urlencoded\")\n",
    "        \n",
    "        logging.info(f\"Created folders: {staging_folder} and {errored_folder} in GCS.\")\n",
    "        \n",
    "        # Initialize S3 Client\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=aws_access_key,\n",
    "            aws_secret_access_key=aws_secret_key\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Fetching New Transcripts to process\")\n",
    "        response = s3_client.list_objects_v2(Bucket=s3_analysis_bucket, Prefix=s3_transcript_location)\n",
    "        \n",
    "        all_files = []\n",
    "        for obj in response.get('Contents', []):\n",
    "            if obj['Key'].endswith('.json'):\n",
    "                file_path = obj['Key']\n",
    "                s3_ts = obj['LastModified']\n",
    "                \n",
    "                call_id = file_path.split('/')[-1].split(\"_analysis_\")[0]\n",
    "                TIMESTAMP = datetime.strptime(file_path.split('analysis_')[-1].split('.')[0].replace('_', ':'), '%Y-%m-%dT%H:%M:%SZ')    \n",
    "        \n",
    "                all_files.append({\n",
    "                    'File': file_path,\n",
    "                    'ID': call_id,\n",
    "                    'File_TIMESTAMP': TIMESTAMP,\n",
    "                    'File_Date': TIMESTAMP.strftime('%Y-%m-%d'),\n",
    "                    'File_Time': TIMESTAMP.strftime('%H:%M:%S'),\n",
    "                    'S3_TIMESTAMP': s3_ts,\n",
    "                    'S3_Date': s3_ts.strftime('%Y-%m-%d'),\n",
    "                    'S3_Time': s3_ts.strftime('%H:%M:%S')\n",
    "                })\n",
    "        \n",
    "        files_sorted = pd.DataFrame(all_files).sort_values(['File_TIMESTAMP'], ascending=False, ignore_index=True)\n",
    "        \n",
    "        # Write DataFrame to the correct GCS path\n",
    "        csv_path = f\"gs://{vai_gcs_bucket}/{staging_folder}/{pipeline_run_name}_S3_Transcripts_fetched.csv\"\n",
    "        files_sorted.to_csv(csv_path, index=False)\n",
    "        \n",
    "        logger.info(f\"Written Transcripts to GCS Bucket: {csv_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        handle_exception(\"N/A\", vai_gcs_bucket, pipeline_run_name, errored_folder, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3591c203-f605-4bfb-b5b9-e4b15791c4ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Component: Process Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabdde1c-b340-427c-9092-0b1e96dd7c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13426e4d-a28c-4416-a24b-228df8f6da01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d5ca7-03cd-4629-ac8e-50df45336bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78e8767d-24ba-4713-a6d4-00be95aa4c0e",
   "metadata": {},
   "source": [
    "# Define the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8b8fae6e-1f9c-4ab9-8330-ddd074a3fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=VAI_GCP_PIPELINE_RUN_NAME,\n",
    "    description=\"Proces Amazon Audio Transcripts to KPIs\"\n",
    ")\n",
    "def vai_audio_to_kpi_pipeline(\n",
    "    pipeline_run_name: str,\n",
    "    aws_access_key: str,\n",
    "    aws_secret_key: str,\n",
    "    s3_analysis_bucket: str,\n",
    "    s3_transcript_location: str,\n",
    "    vai_gcs_bucket: str,\n",
    "    max_objects: int\n",
    "):\n",
    "    fetch_transcripts = list_s3_files_to_gcs(\n",
    "        pipeline_run_name=VAI_GCP_PIPELINE_RUN_NAME,\n",
    "        aws_access_key=VAI_AWS_ACCESS_KEY,\n",
    "        aws_secret_key=VAI_AWS_SECRET_KEY,\n",
    "        s3_analysis_bucket=VAI_S3_ANALYSIS_BUCKET,\n",
    "        s3_transcript_location=VAI_S3_TRANSCRIPTS_LOCATION,\n",
    "        vai_gcs_bucket=VAI_GCP_PIPELINE_BUCKET,\n",
    "        max_objects=max_objects\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de9f8e-1b71-4632-b429-b38c7f642abd",
   "metadata": {},
   "source": [
    "# Compile the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25c4a84f-936d-43b2-8bea-9c42f298b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(vai_audio_to_kpi_pipeline, f'{VAI_GCP_PIPELINE_NAME}.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4395ac4-60c0-4607-aabf-23f5f31f9ca7",
   "metadata": {},
   "source": [
    "# Run the Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6117d409-5818-4656-ac27-64b7ea9ab747",
   "metadata": {},
   "source": [
    "## Run in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f82dae3d-a209-41df-af85-97d715d94fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "aiplatform.init(project=VAI_GCP_PROJECT_ID, location=VAI_GCP_PROJECT_LOCATION)\n",
    "\n",
    "max_objects = 1\n",
    "\n",
    "# Create pipeline job\n",
    "job = pipeline_jobs.PipelineJob(\n",
    "    display_name = f\"{VAI_GCP_PIPELINE_RUN_NAME}\".lower(),\n",
    "    job_id = f\"vai-pipeline-run-{TIMESTAMP}\".lower(),\n",
    "    template_path = f\"{VAI_GCP_PIPELINE_NAME}.yaml\",\n",
    "    pipeline_root = f\"gs://{VAI_GCP_PIPELINE_BUCKET}\",\n",
    "    project = VAI_GCP_PROJECT_ID,\n",
    "    location = VAI_GCP_PROJECT_LOCATION,\n",
    "    enable_caching = False,\n",
    "    parameter_values={\n",
    "        \"pipeline_run_name\":VAI_GCP_PIPELINE_RUN_NAME,\n",
    "        \"aws_access_key\":VAI_AWS_ACCESS_KEY,\n",
    "        \"aws_secret_key\":VAI_AWS_SECRET_KEY,\n",
    "        \"s3_analysis_bucket\":VAI_S3_ANALYSIS_BUCKET,\n",
    "        \"s3_transcript_location\":VAI_S3_TRANSCRIPTS_LOCATION,\n",
    "        \"vai_gcs_bucket\":VAI_GCP_PIPELINE_BUCKET,\n",
    "        \"max_objects\":max_objects\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d0b3a463-dbc3-465c-a7c3-9459f26b2298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/275963620760/locations/us-central1/pipelineJobs/vai-pipeline-run-2025-03-02-17-00-46\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/275963620760/locations/us-central1/pipelineJobs/vai-pipeline-run-2025-03-02-17-00-46')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/vai-pipeline-run-2025-03-02-17-00-46?project=275963620760\n",
      "PipelineJob projects/275963620760/locations/us-central1/pipelineJobs/vai-pipeline-run-2025-03-02-17-00-46 current state:\n",
      "3\n",
      "PipelineJob projects/275963620760/locations/us-central1/pipelineJobs/vai-pipeline-run-2025-03-02-17-00-46 current state:\n",
      "3\n",
      "PipelineJob projects/275963620760/locations/us-central1/pipelineJobs/vai-pipeline-run-2025-03-02-17-00-46 current state:\n",
      "3\n",
      "PipelineJob projects/275963620760/locations/us-central1/pipelineJobs/vai-pipeline-run-2025-03-02-17-00-46 current state:\n",
      "3\n",
      "PipelineJob projects/275963620760/locations/us-central1/pipelineJobs/vai-pipeline-run-2025-03-02-17-00-46 current state:\n",
      "3\n",
      "PipelineJob run completed. Resource name: projects/275963620760/locations/us-central1/pipelineJobs/vai-pipeline-run-2025-03-02-17-00-46\n"
     ]
    }
   ],
   "source": [
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362431c-209a-4f36-b98a-b1894eb429d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posigen",
   "language": "python",
   "name": "posiegen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
